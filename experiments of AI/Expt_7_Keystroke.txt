Exp No
: 7                                                                                                                                                Date:                                                                                         
 
EXPLORE KEYSTROKE RECOGNITION USING NLP  
 
 
Aim: To explore Keystroke recognition using NLP  
 
Algorithm:  
 
1. Import Libraries: Import numpy, pandas, matplotlib, and sklearn libraries for data handling, plotting, and 
modeling.  
2. Load Dataset: Load keystroke dataset from the URL into a DataFrame.  
3. Calculate Latency Averages: Extract latency columns (starting with "DD"), calculate average latency per 
subject, and plot the first six subjects.  
4. Split Data: Split data into 80% training and 20% testing sets.  
5. Define Features and Labels: Set feature (X_train, X_test) and label (y_train, y_test) sets for training and 
testing.  
6. Train Classifiers: Train three classifiers (KNN, SVC, MLP) on the training set, predict on X_test, and 
calculate accuracy for each.  
7. Display Accuracies: Print accuracy scores for each classifier.  
8. Confusion Matrix: Create and plot a confusion matrix for the predictions of the last classifier.  
 
Program  
import numpy as np  
import pandas as pd  
from matplotlib import pyplot as plt  
%matplotlib inline  
from sklearn.model _selection import train_test_split  
from sklearn import metrics  
from sklearn.neighbors import KNeighborsClassifier  
from sklearn import svm  
from sklearn.neural_network import MLPClassifier  
pwd_data = pd.read_csv("C:/Users/dhari/OneDrive/Desktop/AI IN CS/DSL -StrongPasswordData.csv", header 
= 0) 
# Average Keystroke Latency per Subject  
DD = [dd for dd in pwd_data.columns if dd.startswith('DD')]  
plot = pwd_data[DD]  
plot['subject'] = pwd_data['subject'].values  
plot = plot.groupby('subject').mean()  
plot.iloc[:6].T.plot(figsize=(8, 6), title='Average Keystroke Latency per Subject')  
data_train, data_test = train_test_split(pwd_data, test_size = 0.2,  
random_state=0)  
X_train = data_train[pwd_data.columns[2:]]  
y_train = data_train['subject']  
X_test = data_test[pwd_data.columns[2:]]  
y_test = data_test['subject']  
# K-Nearest Neighbor Classifier  29 
 knc = KNeighborsClassifier()  
 
knc.fit(X_train, y_train)  
y_pred = knc.predict(X_test)  
knc_accuracy = metrics.accuracy_score(y_test, y_pred)  
print('K -Nearest Neighbor  Classifier Accuracy:', knc_accuracy)  
svc = svm.SVC(kernel='linear')  
svc.fit(X_train, y_train)  
y_pred = svc.predict(X_test)  
svc_accuracy = metrics. accuracy_score(y_test, y_pred)  
print('Support Vector Linear Classifier Accuracy:', svc_accuracy)  
mlpc = MLPClassifier()  
mlpc.fit(X_train,y_train)  
y_pred = mlpc.predict(X_test)  
mlpc_accuracy = metrics.accuracy_score(y_test, y_pred)  
print('Multi Layer Perceptron Classifier Accuracy:', mlpc_accuracy)  
 
 
Output  
 
 
            Result:     
 
             
 
30